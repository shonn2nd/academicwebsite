---
title: "SEM (notes for myself)"
authors: 
  - admin
tags: [R, stats]
date: "2025-07-02"
categories: 
  - R
output:
  md_document:
    variant: gfm
    preserve_yaml: true
    toc: false
    toc_depth: 2
math: true
draft: false
---



<div id="p.21" class="section level1">
<h1>p.21</h1>
<div id="covariance-derivation" class="section level2">
<h2>Covariance Derivation</h2>
<p>The covariance between two random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> is defined as:</p>
<p><span class="math display">\[
\text{Cov}(X_1, X_2) = \mathbb{E}\left[(X_1 - \mathbb{E}(X_1))(X_2 - \mathbb{E}(X_2))\right]
\]</span></p>
<div id="step-1-expanding-the-expression" class="section level3">
<h3>Step 1: Expanding the expression</h3>
<p>First, expand the product inside the expectation:</p>
<p><span class="math display">\[
(X_1 - \mathbb{E}(X_1))(X_2 - \mathbb{E}(X_2)) = X_1X_2 - X_1\mathbb{E}(X_2) - \mathbb{E}(X_1)X_2 + \mathbb{E}(X_1)\mathbb{E}(X_2)
\]</span></p>
</div>
<div id="step-2-taking-the-expectation" class="section level3">
<h3>Step 2: Taking the expectation</h3>
<p>Now, take the expectation of both sides:</p>
<p><span class="math display">\[
\mathbb{E}\left[(X_1 - \mathbb{E}(X_1))(X_2 - \mathbb{E}(X_2))\right] = \mathbb{E}(X_1X_2) - \mathbb{E}(X_1)\mathbb{E}(X_2) - \mathbb{E}(X_1)\mathbb{E}(X_2) + \mathbb{E}(X_1)\mathbb{E}(X_2)
\]</span></p>
</div>
<div id="step-3-simplifying-the-result" class="section level3">
<h3>Step 3: Simplifying the result</h3>
<p>Notice that the terms <span class="math inline">\(\mathbb{E}(X_1)\mathbb{E}(X_2)\)</span> cancel out:</p>
<p><span class="math display">\[
\mathbb{E}(X_1X_2) - \mathbb{E}(X_1)\mathbb{E}(X_2)
\]</span></p>
<p>Thus, we arrive at the final formula for the covariance:</p>
<p><span class="math display">\[
\text{Cov}(X_1, X_2) = \mathbb{E}(X_1X_2) - \mathbb{E}(X_1)\mathbb{E}(X_2)
\]</span></p>
<hr />
</div>
</div>
</div>
<div id="p.22" class="section level1">
<h1>p.22</h1>
<div id="covariance-derivation-in-confirmatory-factor-analysis" class="section level2">
<h2>Covariance Derivation in Confirmatory Factor Analysis</h2>
<p>We start with the observed variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>:</p>
<p><span class="math display">\[
x_1 = \lambda_1 \xi_1 + \delta_1
\]</span></p>
<p><span class="math display">\[
x_2 = \lambda_2 \xi_1 + \delta_2
\]</span></p>
<p>We want to find <span class="math inline">\(\text{Cov}(x_1, x_2)\)</span>:</p>
<p><span class="math display">\[
\text{Cov}(x_1, x_2) = \text{Cov}(\lambda_1 \xi_1 + \delta_1, \lambda_2 \xi_1 + \delta_2)
\]</span></p>
<p>Using bilinearity of covariance:</p>
<p><span class="math display">\[
= \lambda_1 \lambda_2 \text{Cov}(\xi_1, \xi_1) + \lambda_1 \text{Cov}(\xi_1, \delta_2) + \lambda_2 \text{Cov}(\delta_1, \xi_1) + \text{Cov}(\delta_1, \delta_2)
\]</span></p>
<p>Assuming:<br />
- <span class="math inline">\(\text{Cov}(\xi_1, \delta_2) = 0\)</span><br />
- <span class="math inline">\(\text{Cov}(\delta_1, \xi_1) = 0\)</span><br />
- <span class="math inline">\(\text{Cov}(\delta_1, \delta_2) = 0\)</span><br />
- <span class="math inline">\(\text{Var}(\xi_1) = \phi_{11}\)</span><br />
</p>
<p>Then:</p>
<p><span class="math display">\[
\text{Cov}(x_1, x_2) = \lambda_1 \lambda_2 \phi_{11}
\]</span></p>
<hr />
</div>
</div>
<div id="p.23" class="section level1">
<h1>p.23</h1>
<div id="derivation-covx-c-0" class="section level2">
<h2>1. Derivation: Cov(x, c′) = 0</h2>
<p>Let <span class="math inline">\(\mathbf{x}\)</span> be a random vector and <span class="math inline">\(\mathbf{c}\)</span> a constant vector.</p>
<p><span class="math display">\[
\text{Cov}(\mathbf{x}, \mathbf{c}^\top) = \mathbb{E} \left[ (\mathbf{x} - \mathbb{E}[\mathbf{x}])(\mathbf{c}^\top - \mathbb{E}[\mathbf{c}^\top]) \right]
\]</span></p>
<p>But since <span class="math inline">\(\mathbf{c}^\top\)</span> is constant, <span class="math inline">\(\mathbb{E}[\mathbf{c}^\top] = \mathbf{c}^\top\)</span>, so:</p>
<p><span class="math display">\[
\mathbf{c}^\top - \mathbb{E}[\mathbf{c}^\top] = \mathbf{0}
\]</span></p>
<p>Hence:</p>
<p><span class="math display">\[
\text{Cov}(\mathbf{x}, \mathbf{c}^\top) = \mathbb{E} \left[ (\mathbf{x} - \mathbb{E}[\mathbf{x}]) \cdot \mathbf{0} \right] = \mathbf{0}
\]</span></p>
</div>
<div id="derivation-varx-covx-x-σ" class="section level2">
<h2>2. Derivation: Var(x) = Cov(x, x′) = Σ</h2>
<p>By definition:</p>
<p><span class="math display">\[
\text{Var}(\mathbf{x}) = \text{Cov}(\mathbf{x}, \mathbf{x}^\top) = \mathbb{E} \left[ (\mathbf{x} - \mathbb{E}[\mathbf{x}])(\mathbf{x} - \mathbb{E}[\mathbf{x}])^\top \right]
\]</span></p>
<p>This is the population covariance matrix, denoted as:</p>
<p><span class="math display">\[
\boldsymbol{\Sigma}
\]</span></p>
</div>
<div id="numerical-example-in-r" class="section level2">
<h2>3. Numerical Example in R</h2>
<pre class="r"><code># Set seed and generate data
set.seed(123)

# Simulate random vector x (5 observations, 3 variables)
x &lt;- matrix(c(1, 2, 3, 4, 5,
              2, 3, 4, 5, 6,
              5, 4, 3, 2, 1), ncol = 3)

x</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,]    1    2    5
## [2,]    2    3    4
## [3,]    3    4    3
## [4,]    4    5    2
## [5,]    5    6    1</code></pre>
<pre class="r"><code>x_centered &lt;- scale(x, center = TRUE, scale = FALSE)
x_centered</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,]   -2   -2    2
## [2,]   -1   -1    1
## [3,]    0    0    0
## [4,]    1    1   -1
## [5,]    2    2   -2
## attr(,&quot;scaled:center&quot;)
## [1] 3 4 3</code></pre>
</div>
<div id="confirm-varx-covx-x" class="section level2">
<h2>4. Confirm Var(x) = Cov(x, x′)</h2>
<pre class="r"><code># Compute covariance matrix of x manually
# population covariance matrix
Sigma_manual_p &lt;- t(x_centered) %*% x_centered / (nrow(x))
Sigma_manual_p</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,]    2    2   -2
## [2,]    2    2   -2
## [3,]   -2   -2    2</code></pre>
<pre class="r"><code># sample covariance matrix
Sigma_manual_s &lt;- t(x_centered) %*% x_centered / (nrow(x) - 1)
Sigma_manual_s</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,]  2.5  2.5 -2.5
## [2,]  2.5  2.5 -2.5
## [3,] -2.5 -2.5  2.5</code></pre>
<pre class="r"><code># Compare with built-in cov()
# sample covariance matrix
Sigma_builtin &lt;- cov(x)
Sigma_builtin</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,]  2.5  2.5 -2.5
## [2,]  2.5  2.5 -2.5
## [3,] -2.5 -2.5  2.5</code></pre>
<hr />
</div>
</div>
<div id="p.28" class="section level1">
<h1>p.28</h1>
<div id="step-1-create-the-data-for-disposable-income-and-consumers-expenditures" class="section level2">
<h2>Step 1: Create the data for Disposable Income and Consumers’ Expenditures</h2>
<pre class="r"><code>income &lt;- c(433, 483, 479, 486, 494, 498, 511, 534, 478, 440, 372, 381, 419, 449, 511, 520, 477, 517, 548, 629)

consum &lt;- c(394, 423, 437, 434, 447, 447, 466, 474, 439, 399, 350, 364, 392, 416, 463, 469, 444, 471, 494, 529)</code></pre>
</div>
<div id="step-2-combine-the-data-into-a-matrix" class="section level2">
<h2>Step 2: Combine the data into a matrix</h2>
<pre class="r"><code>data &lt;- cbind(consum, income)

data</code></pre>
<pre><code>##       consum income
##  [1,]    394    433
##  [2,]    423    483
##  [3,]    437    479
##  [4,]    434    486
##  [5,]    447    494
##  [6,]    447    498
##  [7,]    466    511
##  [8,]    474    534
##  [9,]    439    478
## [10,]    399    440
## [11,]    350    372
## [12,]    364    381
## [13,]    392    419
## [14,]    416    449
## [15,]    463    511
## [16,]    469    520
## [17,]    444    477
## [18,]    471    517
## [19,]    494    548
## [20,]    529    629</code></pre>
</div>
<div id="step-3-center-the-data-by-subtracting-the-mean-of-each-variable" class="section level2">
<h2>Step 3: Center the data by subtracting the mean of each variable</h2>
<pre class="r"><code>Z &lt;- scale(data, center = TRUE, scale = FALSE)  # Centers the data (but doesn&#39;t scale it)
Z</code></pre>
<pre><code>##       consum  income
##  [1,]  -43.6  -49.95
##  [2,]  -14.6    0.05
##  [3,]   -0.6   -3.95
##  [4,]   -3.6    3.05
##  [5,]    9.4   11.05
##  [6,]    9.4   15.05
##  [7,]   28.4   28.05
##  [8,]   36.4   51.05
##  [9,]    1.4   -4.95
## [10,]  -38.6  -42.95
## [11,]  -87.6 -110.95
## [12,]  -73.6 -101.95
## [13,]  -45.6  -63.95
## [14,]  -21.6  -33.95
## [15,]   25.4   28.05
## [16,]   31.4   37.05
## [17,]    6.4   -5.95
## [18,]   33.4   34.05
## [19,]   56.4   65.05
## [20,]   91.4  146.05
## attr(,&quot;scaled:center&quot;)
## consum income 
## 437.60 482.95</code></pre>
</div>
<div id="step-4-compute-z-transpose-of-z" class="section level2">
<h2>Step 4: Compute Z’ (transpose of Z)</h2>
<pre class="r"><code>Z_t &lt;- t(Z)
Z_t</code></pre>
<pre><code>##          [,1]   [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9]  [,10]   [,11]
## consum -43.60 -14.60 -0.60 -3.60  9.40  9.40 28.40 36.40  1.40 -38.60  -87.60
## income -49.95   0.05 -3.95  3.05 11.05 15.05 28.05 51.05 -4.95 -42.95 -110.95
##          [,12]  [,13]  [,14] [,15] [,16] [,17] [,18] [,19]  [,20]
## consum  -73.60 -45.60 -21.60 25.40 31.40  6.40 33.40 56.40  91.40
## income -101.95 -63.95 -33.95 28.05 37.05 -5.95 34.05 65.05 146.05
## attr(,&quot;scaled:center&quot;)
## consum income 
## 437.60 482.95</code></pre>
</div>
<div id="step-5-compute-zz-matrix-multiplication-of-z-and-z" class="section level2">
<h2>Step 5: Compute Z’Z (matrix multiplication of Z’ and Z)</h2>
<pre class="r"><code>Z_t_Z &lt;- Z_t %*% Z
Z_t_Z</code></pre>
<pre><code>##         consum   income
## consum 35886.8 47584.60
## income 47584.6 64992.95</code></pre>
</div>
<div id="step-6-apply-the-1n-1-factor" class="section level2">
<h2>Step 6: Apply the 1/(N-1) factor</h2>
<pre class="r"><code>N &lt;- nrow(Z)  # Number of observations (rows)
cov_matrix_manual &lt;- (1 / (N - 1)) * Z_t_Z

# Display the result
print(cov_matrix_manual)</code></pre>
<pre><code>##          consum   income
## consum 1888.779 2504.453
## income 2504.453 3420.682</code></pre>
<hr />
</div>
</div>
<div id="p.28-1" class="section level1">
<h1>p.28</h1>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In multivariate statistics, it is often important to detect observations that deviate significantly from the center of the multivariate data cloud. One useful tool is the matrix:</p>
<p><span class="math display">\[
\mathbf{A} = \mathbf{Z(Z&#39;Z)^{-1}Z&#39;}
\]</span></p>
<p>Where:</p>
<p><span class="math inline">\(\mathbf{Z}\)</span> is the mean-centered data matrix of size <span class="math inline">\(N \times (p + q)\)</span>,</p>
<p><span class="math inline">\(\mathbf{Z}&#39;\mathbf{Z}\)</span> is the cross-product matrix,</p>
<p><span class="math inline">\((\mathbf{Z}&#39;\mathbf{Z})^{-1}\)</span> is its inverse,</p>
<p><span class="math inline">\(\mathbf{A}\)</span> is a square <span class="math inline">\(N \times N\)</span> matrix whose diagonal entries <span class="math inline">\(a_{ii}\)</span> represent the multivariate “distance” of each observation from the center.</p>
<p>The average value of <span class="math inline">\(a_{ii}\)</span> is:</p>
<p><span class="math display">\[
\frac{(p + q)}{N}
\]</span></p>
<p>Observations with much higher <span class="math inline">\(a_{ii}\)</span> values than the average are potential <strong>multivariate outliers</strong>.</p>
</div>
<div id="step-by-step-example" class="section level2">
<h2>Step-by-Step Example</h2>
<p>We will use a simple example dataset with 3 observations and 2 variables.</p>
<pre class="r"><code># Define the data matrix (3 observations, 2 variables)
X &lt;- matrix(c(2, 3, 4, 4, 6, 5), ncol = 2, byrow = FALSE)
colnames(X) &lt;- c(&quot;X1&quot;, &quot;X2&quot;)
rownames(X) &lt;- paste0(&quot;Obs&quot;, 1:3)
X</code></pre>
<pre><code>##      X1 X2
## Obs1  2  4
## Obs2  3  6
## Obs3  4  5</code></pre>
</div>
<div id="step-1-center-the-data-create-z" class="section level2">
<h2>Step 1: Center the Data (Create Z)</h2>
<p>We subtract the mean from each variable to obtain the matrix <span class="math inline">\(\mathbf{Z}\)</span>.</p>
<pre class="r"><code>Z &lt;- scale(X, center = TRUE, scale = FALSE)
Z</code></pre>
<pre><code>##      X1 X2
## Obs1 -1 -1
## Obs2  0  1
## Obs3  1  0
## attr(,&quot;scaled:center&quot;)
## X1 X2 
##  3  5</code></pre>
</div>
<div id="step-2-compute-mathbfzmathbfz" class="section level2">
<h2>Step 2: Compute <span class="math inline">\(\mathbf{Z}&#39;\mathbf{Z}\)</span></h2>
<pre class="r"><code>ZtZ &lt;- t(Z) %*% Z
ZtZ</code></pre>
<pre><code>##    X1 X2
## X1  2  1
## X2  1  2</code></pre>
</div>
<div id="step-3-compute-mathbfzmathbfz-1" class="section level2">
<h2>Step 3: Compute <span class="math inline">\((\mathbf{Z}&#39;\mathbf{Z})^{-1}\)</span></h2>
<pre class="r"><code>ZtZ_inv &lt;- solve(ZtZ)
ZtZ_inv</code></pre>
<pre><code>##            X1         X2
## X1  0.6666667 -0.3333333
## X2 -0.3333333  0.6666667</code></pre>
</div>
<div id="step-4-compute-mathbfa-mathbfzmathbfzmathbfz-1mathbfz" class="section level2">
<h2>Step 4: Compute <span class="math inline">\(\mathbf{A} = \mathbf{Z}(\mathbf{Z}&#39;\mathbf{Z})^{-1}\mathbf{Z}&#39;\)</span></h2>
<pre class="r"><code>A &lt;- Z %*% ZtZ_inv %*% t(Z)
round(A, 3)</code></pre>
<pre><code>##        Obs1   Obs2   Obs3
## Obs1  0.667 -0.333 -0.333
## Obs2 -0.333  0.667 -0.333
## Obs3 -0.333 -0.333  0.667</code></pre>
</div>
<div id="step-5-extract-diagonal-elements-a_ii" class="section level2">
<h2>Step 5: Extract Diagonal Elements <span class="math inline">\(a_{ii}\)</span></h2>
<p>These diagonal values represent the multivariate distance for each observation.</p>
<pre class="r"><code>a_ii &lt;- diag(A)
names(a_ii) &lt;- rownames(X)
a_ii</code></pre>
<pre><code>##      Obs1      Obs2      Obs3 
## 0.6666667 0.6666667 0.6666667</code></pre>
</div>
<div id="step-6-compare-to-expected-average" class="section level2">
<h2>Step 6: Compare to Expected Average</h2>
<pre class="r"><code>p_plus_q &lt;- ncol(Z)  # total number of observed variables (p + q)
N &lt;- nrow(Z)  # number of observations
expected_mean &lt;- p_plus_q / N
expected_mean</code></pre>
<pre><code>## [1] 0.6666667</code></pre>
<p>Any <span class="math inline">\(a_{ii}\)</span> significantly greater than 0.6666667 may indicate a multivariate outlier.</p>
</div>
<div id="step-7-visualization" class="section level2">
<h2>Step 7: Visualization</h2>
<pre class="r"><code>barplot(a_ii, names.arg = names(a_ii), 
        main = &quot;Multivariate Distance (a_ii) for Each Observation&quot;, 
        ylab = &quot;a_ii&quot;, col = &quot;skyblue&quot;, ylim = c(0, 1))
abline(h = expected_mean, col = &quot;red&quot;, lty = 2)
legend(&quot;topright&quot;, legend = paste(&quot;Expected Mean =&quot;, round(expected_mean, 3)), 
       col = &quot;red&quot;, lty = 2)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<ul>
<li>Matrix <span class="math inline">\(\mathbf{A} = \mathbf{Z(Z&#39;Z)^{-1}Z&#39;}\)</span> provides a way to measure the multivariate distance of each observation.</li>
<li>Diagonal values <span class="math inline">\(a_{ii}\)</span> indicate how far each case is from the multivariate mean.</li>
<li>The average of the <span class="math inline">\(a_{ii}\)</span>’s is <span class="math inline">\(\frac{(p + q)}{N}\)</span>, which provides a benchmark.</li>
<li>Observations with high <span class="math inline">\(a_{ii}\)</span> values are flagged as potential <strong>outliers</strong> in multivariate space.</li>
</ul>
<p>This method is especially helpful in the context of SEM, factor analysis, or other multivariate procedures where unusual cases may affect model fit or estimates.</p>
<hr />
</div>
</div>
<div id="p.-30" class="section level1">
<h1>p. 30</h1>
<div id="introduction-1" class="section level2">
<h2>Introduction</h2>
<p>The formula for calculating multidimensional outliers:</p>
<p><span class="math display">\[
Z(Z&#39;Z)^{-1}Z&#39;
\]</span></p>
<p>Where:</p>
<p><span class="math inline">\(Z\)</span> is the standardized data matrix.</p>
<p><span class="math inline">\(Z&#39;Z\)</span> is the product of the transposed <span class="math inline">\(Z\)</span> matrix and <span class="math inline">\(Z\)</span> itself.</p>
<p><span class="math inline">\((Z&#39;Z)^{-1}\)</span> is the inverse of the matrix <span class="math inline">\(Z&#39;Z\)</span>.</p>
<p>The final result gives a measure of how far each observation is from the multivariate centroid.</p>
<p>We will apply this formula to a dataset that contains estimates of cloud cover (COVER1, COVER2, COVER3).</p>
</div>
<div id="data-preparation" class="section level2">
<h2>Data Preparation</h2>
<pre class="r"><code># Define the data
data &lt;- data.frame(
  COVER1 = c(0, 20, 80, 50, 5, 1, 5, 0, 10, 0, 0, 10, 0, 10, 0, 0, 5, 10, 20, 35, 90, 50, 35, 25, 0, 0, 10, 40, 35, 55, 35, 0, 0, 5, 20, 0, 0, 0, 15, 95, 40, 40, 15, 30, 75, 100, 100, 100, 100, 100, 100, 100, 0, 5, 80, 80, 80, 40, 20, 1),
  COVER2 = c(5, 20, 85, 50, 2, 1, 5, 0, 15, 0, 0, 30, 2, 10, 0, 0, 0, 20, 45, 75, 99, 90, 85, 15, 0, 0, 10, 75, 70, 90, 95, 0, 0, 1, 60, 0, 0, 0, 55, 0, 35, 50, 60, 30, 85, 100, 90, 95, 95, 99, 30, 5, 0, 5, 90, 95, 90, 55, 40, 0),
  COVER3 = c(0, 20, 90, 70, 5, 2, 2, 0, 5, 0, 0, 10, 2, 5, 0, 0, 20, 20, 15, 60, 100, 80, 70, 40, 0, 0, 20, 30, 20, 90, 80, 0, 0, 2, 50, 0, 0, 0, 50, 40, 30, 40, 5, 15, 75, 100, 85, 100, 100, 100, 95, 95, 0, 5, 85, 80, 70, 50, 5, 0)
)

dplyr::glimpse(data)</code></pre>
<pre><code>## Rows: 60
## Columns: 3
## $ COVER1 &lt;dbl&gt; 0, 20, 80, 50, 5, 1, 5, 0, 10, 0, 0, 10, 0, 10, 0, 0, 5, 10, 20…
## $ COVER2 &lt;dbl&gt; 5, 20, 85, 50, 2, 1, 5, 0, 15, 0, 0, 30, 2, 10, 0, 0, 0, 20, 45…
## $ COVER3 &lt;dbl&gt; 0, 20, 90, 70, 5, 2, 2, 0, 5, 0, 0, 10, 2, 5, 0, 0, 20, 20, 15,…</code></pre>
<pre class="r"><code># View the data to check it
head(data)</code></pre>
<pre><code>##   COVER1 COVER2 COVER3
## 1      0      5      0
## 2     20     20     20
## 3     80     85     90
## 4     50     50     70
## 5      5      2      5
## 6      1      1      2</code></pre>
</div>
<div id="mean-centering" class="section level2">
<h2>Mean-Centering</h2>
<p>We will now mean-center the data to create the Z matrix.</p>
<pre class="r"><code># Mean-centering the data (subtracting the mean of each column from the data)
Z &lt;- scale(data, center = TRUE, scale = FALSE)

Z</code></pre>
<pre><code>##       COVER1 COVER2 COVER3
##  [1,] -32.95 -32.65 -35.55
##  [2,] -12.95 -17.65 -15.55
##  [3,]  47.05  47.35  54.45
##  [4,]  17.05  12.35  34.45
##  [5,] -27.95 -35.65 -30.55
##  [6,] -31.95 -36.65 -33.55
##  [7,] -27.95 -32.65 -33.55
##  [8,] -32.95 -37.65 -35.55
##  [9,] -22.95 -22.65 -30.55
## [10,] -32.95 -37.65 -35.55
## [11,] -32.95 -37.65 -35.55
## [12,] -22.95  -7.65 -25.55
## [13,] -32.95 -35.65 -33.55
## [14,] -22.95 -27.65 -30.55
## [15,] -32.95 -37.65 -35.55
## [16,] -32.95 -37.65 -35.55
## [17,] -27.95 -37.65 -15.55
## [18,] -22.95 -17.65 -15.55
## [19,] -12.95   7.35 -20.55
## [20,]   2.05  37.35  24.45
## [21,]  57.05  61.35  64.45
## [22,]  17.05  52.35  44.45
## [23,]   2.05  47.35  34.45
## [24,]  -7.95 -22.65   4.45
## [25,] -32.95 -37.65 -35.55
## [26,] -32.95 -37.65 -35.55
## [27,] -22.95 -27.65 -15.55
## [28,]   7.05  37.35  -5.55
## [29,]   2.05  32.35 -15.55
## [30,]  22.05  52.35  54.45
## [31,]   2.05  57.35  44.45
## [32,] -32.95 -37.65 -35.55
## [33,] -32.95 -37.65 -35.55
## [34,] -27.95 -36.65 -33.55
## [35,] -12.95  22.35  14.45
## [36,] -32.95 -37.65 -35.55
## [37,] -32.95 -37.65 -35.55
## [38,] -32.95 -37.65 -35.55
## [39,] -17.95  17.35  14.45
## [40,]  62.05 -37.65   4.45
## [41,]   7.05  -2.65  -5.55
## [42,]   7.05  12.35   4.45
## [43,] -17.95  22.35 -30.55
## [44,]  -2.95  -7.65 -20.55
## [45,]  42.05  47.35  39.45
## [46,]  67.05  62.35  64.45
## [47,]  67.05  52.35  49.45
## [48,]  67.05  57.35  64.45
## [49,]  67.05  57.35  64.45
## [50,]  67.05  61.35  64.45
## [51,]  67.05  -7.65  59.45
## [52,]  67.05 -32.65  59.45
## [53,] -32.95 -37.65 -35.55
## [54,] -27.95 -32.65 -30.55
## [55,]  47.05  52.35  49.45
## [56,]  47.05  57.35  44.45
## [57,]  47.05  52.35  34.45
## [58,]   7.05  17.35  14.45
## [59,] -12.95   2.35 -30.55
## [60,] -31.95 -37.65 -35.55
## attr(,&quot;scaled:center&quot;)
## COVER1 COVER2 COVER3 
##  32.95  37.65  35.55</code></pre>
<pre class="r"><code># Check the mean-centered data (Z matrix)
head(Z)</code></pre>
<pre><code>##      COVER1 COVER2 COVER3
## [1,] -32.95 -32.65 -35.55
## [2,] -12.95 -17.65 -15.55
## [3,]  47.05  47.35  54.45
## [4,]  17.05  12.35  34.45
## [5,] -27.95 -35.65 -30.55
## [6,] -31.95 -36.65 -33.55</code></pre>
</div>
<div id="calculating-zz" class="section level2">
<h2>Calculating <span class="math inline">\(Z&#39;Z\)</span></h2>
<p>Next, we compute the product of the transposed matrix <span class="math inline">\(Z\)</span> and the matrix <span class="math inline">\(Z\)</span>.</p>
<pre class="r"><code># Calculate Z&#39;Z (transposed Z matrix multiplied by Z)
ZZT &lt;- t(Z) %*% Z

# View the result of Z&#39;Z
ZZT</code></pre>
<pre><code>##          COVER1   COVER2   COVER3
## COVER1 76734.85 60191.95 72989.65
## COVER2 60191.95 86335.65 70795.55
## COVER3 72989.65 70795.55 82812.85</code></pre>
</div>
<div id="inverse-of-zz" class="section level2">
<h2>Inverse of <span class="math inline">\(Z&#39;Z\)</span></h2>
<p>Now, we calculate the inverse of the matrix <span class="math inline">\(Z&#39;Z\)</span>.</p>
<pre class="r"><code># Calculate the inverse of Z&#39;Z
ZZT_inv &lt;- solve(ZZT)

# View the inverse of Z&#39;Z
ZZT_inv</code></pre>
<pre><code>##               COVER1        COVER2        COVER3
## COVER1  8.186873e-05  6.996057e-06 -7.813835e-05
## COVER2  6.996057e-06  3.933723e-05 -3.979504e-05
## COVER3 -7.813835e-05 -3.979504e-05  1.149653e-04</code></pre>
</div>
<div id="calculate-zzz-1z" class="section level2">
<h2>Calculate <span class="math inline">\(Z(Z&#39;Z)^{-1}Z&#39;\)</span></h2>
<p>Finally, using the inverse of <span class="math inline">\(Z&#39;Z\)</span>, we compute the multidimensional outlier scores.</p>
<pre class="r"><code># Calculate the multidimensional outliers
outliers &lt;- Z %*% ZZT_inv %*% t(Z)

# Extract the diagonal of the outlier matrix (outlier scores)
outlier_scores &lt;- diag(outliers)

# View the outlier scores for each observation
outlier_scores</code></pre>
<pre><code>##  [1] 0.015726795 0.003667134 0.035888471 0.043531791 0.015067469 0.016818904
##  [7] 0.014336636 0.017711895 0.013230015 0.017711895 0.017711895 0.015735922
## [13] 0.016767037 0.012571539 0.017711895 0.017711895 0.047722524 0.011226588
## [19] 0.033505745 0.044503013 0.051723149 0.067601060 0.085473686 0.043702080
## [25] 0.017711895 0.017711895 0.019881286 0.088784132 0.115257068 0.090112579
## [31] 0.141386847 0.017711895 0.017711895 0.016124246 0.056874143 0.017711895
## [37] 0.017711895 0.017711895 0.078447969 0.310744264 0.012569282 0.004286889
## [43] 0.116357798 0.029894426 0.031821437 0.061860674 0.081910183 0.059274389
## [49] 0.059274389 0.061186068 0.182763526 0.317232262 0.017711895 0.013128462
## [55] 0.034993660 0.045793479 0.063100245 0.005752862 0.064705791 0.017427449</code></pre>
<pre class="r"><code>sum(outlier_scores)</code></pre>
<pre><code>## [1] 3</code></pre>
</div>
<div id="sample-covariance-matrix" class="section level2">
<h2>Sample Covariance Matrix</h2>
<pre class="r"><code>Z_t &lt;- t(Z)
Z_t</code></pre>
<pre><code>##          [,1]   [,2]  [,3]  [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]
## COVER1 -32.95 -12.95 47.05 17.05 -27.95 -31.95 -27.95 -32.95 -22.95 -32.95
## COVER2 -32.65 -17.65 47.35 12.35 -35.65 -36.65 -32.65 -37.65 -22.65 -37.65
## COVER3 -35.55 -15.55 54.45 34.45 -30.55 -33.55 -33.55 -35.55 -30.55 -35.55
##         [,11]  [,12]  [,13]  [,14]  [,15]  [,16]  [,17]  [,18]  [,19] [,20]
## COVER1 -32.95 -22.95 -32.95 -22.95 -32.95 -32.95 -27.95 -22.95 -12.95  2.05
## COVER2 -37.65  -7.65 -35.65 -27.65 -37.65 -37.65 -37.65 -17.65   7.35 37.35
## COVER3 -35.55 -25.55 -33.55 -30.55 -35.55 -35.55 -15.55 -15.55 -20.55 24.45
##        [,21] [,22] [,23]  [,24]  [,25]  [,26]  [,27] [,28]  [,29] [,30] [,31]
## COVER1 57.05 17.05  2.05  -7.95 -32.95 -32.95 -22.95  7.05   2.05 22.05  2.05
## COVER2 61.35 52.35 47.35 -22.65 -37.65 -37.65 -27.65 37.35  32.35 52.35 57.35
## COVER3 64.45 44.45 34.45   4.45 -35.55 -35.55 -15.55 -5.55 -15.55 54.45 44.45
##         [,32]  [,33]  [,34]  [,35]  [,36]  [,37]  [,38]  [,39]  [,40] [,41]
## COVER1 -32.95 -32.95 -27.95 -12.95 -32.95 -32.95 -32.95 -17.95  62.05  7.05
## COVER2 -37.65 -37.65 -36.65  22.35 -37.65 -37.65 -37.65  17.35 -37.65 -2.65
## COVER3 -35.55 -35.55 -33.55  14.45 -35.55 -35.55 -35.55  14.45   4.45 -5.55
##        [,42]  [,43]  [,44] [,45] [,46] [,47] [,48] [,49] [,50] [,51]  [,52]
## COVER1  7.05 -17.95  -2.95 42.05 67.05 67.05 67.05 67.05 67.05 67.05  67.05
## COVER2 12.35  22.35  -7.65 47.35 62.35 52.35 57.35 57.35 61.35 -7.65 -32.65
## COVER3  4.45 -30.55 -20.55 39.45 64.45 49.45 64.45 64.45 64.45 59.45  59.45
##         [,53]  [,54] [,55] [,56] [,57] [,58]  [,59]  [,60]
## COVER1 -32.95 -27.95 47.05 47.05 47.05  7.05 -12.95 -31.95
## COVER2 -37.65 -32.65 52.35 57.35 52.35 17.35   2.35 -37.65
## COVER3 -35.55 -30.55 49.45 44.45 34.45 14.45 -30.55 -35.55
## attr(,&quot;scaled:center&quot;)
## COVER1 COVER2 COVER3 
##  32.95  37.65  35.55</code></pre>
<pre class="r"><code>Z_t_Z &lt;- Z_t %*% Z
Z_t_Z</code></pre>
<pre><code>##          COVER1   COVER2   COVER3
## COVER1 76734.85 60191.95 72989.65
## COVER2 60191.95 86335.65 70795.55
## COVER3 72989.65 70795.55 82812.85</code></pre>
<pre class="r"><code>N &lt;- nrow(Z)  # Number of observations (rows)
cov_matrix_manual &lt;- (1 / (N - 1)) * Z_t_Z

# Display the result
print(cov_matrix_manual)</code></pre>
<pre><code>##          COVER1   COVER2   COVER3
## COVER1 1300.591 1020.203 1237.113
## COVER2 1020.203 1463.316 1199.925
## COVER3 1237.113 1199.925 1403.608</code></pre>
</div>
</div>
<div id="p.-35" class="section level1">
<h1>p. 35</h1>
<div id="covariance-decomposition-derivation" class="section level2">
<h2>Covariance Decomposition Derivation</h2>
<p>We are given the covariance expression for two variables, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_4\)</span>:</p>
<p><span class="math display">\[
\text{COV}(x_1, x_4) = \text{COV}(\lambda_{11} \xi_1 + \delta_1, \lambda_{41} \xi_1 + \delta_4)
\]</span></p>
</div>
<div id="step-by-step-derivation" class="section level2">
<h2>Step-by-Step Derivation:</h2>
<ol style="list-style-type: decimal">
<li><p><strong>Start with the covariance formula</strong>:<br />
We are looking at the covariance between two linear combinations of random variables:</p>
<p><span class="math display">\[
\text{COV}(a + b, c + d)
\]</span></p>
<p>The general covariance formula for two linear combinations is:</p>
<p><span class="math display">\[
\text{COV}(a + b, c + d) = \text{COV}(a, c) + \text{COV}(a, d) + \text{COV}(b, c) + \text{COV}(b, d)
\]</span></p>
<p>In our case, the random variables are <span class="math inline">\(\lambda_{11} \xi_1 + \delta_1\)</span> and <span class="math inline">\(\lambda_{41} \xi_1 + \delta_4\)</span>.</p></li>
<li><p><strong>Applying the formula</strong>:<br />
Expanding the covariance expression:</p>
<p><span class="math display">\[
\text{COV}(\lambda_{11} \xi_1 + \delta_1, \lambda_{41} \xi_1 + \delta_4)
\]</span></p>
<p>Since <span class="math inline">\(\lambda_{11}\)</span> and <span class="math inline">\(\lambda_{41}\)</span> are constants, we can take them outside of the covariance:</p>
<p><span class="math display">\[
\text{COV}(\lambda_{11} \xi_1 + \delta_1, \lambda_{41} \xi_1 + \delta_4) = \lambda_{11} \lambda_{41} \cdot \text{COV}(\xi_1, \xi_1) + \lambda_{11} \cdot \text{COV}(\xi_1, \delta_4) + \lambda_{41} \cdot \text{COV}(\delta_1, \xi_1) + \text{COV}(\delta_1, \delta_4)
\]</span></p></li>
<li><p><strong>Simplifying the terms</strong>:</p>
<ul>
<li><span class="math inline">\(\text{COV}(\xi_1, \xi_1) = \phi_{11}\)</span> (the variance of <span class="math inline">\(\xi_1\)</span>)</li>
<li><span class="math inline">\(\text{COV}(\xi_1, \delta_4) = 0\)</span> (assuming <span class="math inline">\(\xi_1\)</span> and <span class="math inline">\(\delta_4\)</span> are independent)</li>
<li><span class="math inline">\(\text{COV}(\delta_1, \xi_1) = 0\)</span> (assuming <span class="math inline">\(\delta_1\)</span> and <span class="math inline">\(\xi_1\)</span> are independent)</li>
<li><span class="math inline">\(\text{COV}(\delta_1, \delta_4) = 0\)</span> (assuming <span class="math inline">\(\delta_1\)</span> and <span class="math inline">\(\delta_4\)</span> are uncorrelated)</li>
</ul>
<p>Therefore, the expression simplifies to:</p>
<p><span class="math display">\[
\text{COV}(x_1, x_4) = \lambda_{11} \lambda_{41} \cdot \phi_{11}
\]</span></p></li>
</ol>
</div>
<div id="conclusion-1" class="section level2">
<h2>Conclusion:</h2>
<p>The covariance between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_4\)</span> is:</p>
<p><span class="math display">\[
\text{COV}(x_1, x_4) = \lambda_{11} \lambda_{41} \phi_{11}
\]</span></p>
<hr />
</div>
</div>
